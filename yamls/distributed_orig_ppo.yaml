name: compose-rl-distributed-orig-ppo

scheduling:
  priority: low
  preemptible: true

compute:
  gpus: 8
  cluster: r5z2p1

integrations:
- integration_type: git_repo
  path: /workspace/compose-rl
  git_repo: databricks/compose-rl
  git_branch: ethantang-db/orig_yaml
- integration_type: git_repo
  path: /workspace/research-universe
  git_repo: databricks-mosaic/research-universe
  ssh_clone: true
  git_branch: update-orl-eval

image: mosaicml/dle:nightly-latest

command: |-
  python -m uv pip install --system /workspace/research-universe/minieval
  python -m uv pip install --system /workspace/research-universe/orl_eval
  python -m uv pip install --system /workspace/compose-rl[gpu] --no-deps

  cd /workspace/compose-rl
  composer test_single_controller_ppo.py --file_path /mnt/config/parameters.yaml

env_variables:
  AWS_PROFILE: data-force-one
  AWS_MAX_ATTEMPTS: 10
  LLM_FOUNDRY_SAVE_FOLDER_HF_MAX_SHARD_SIZE: 5GB
  NCCL_CUMEM_ENABLE: 0
  GLOO_SOCKET_IFNAME: eth0
  TP_SOCKET_IFNAME: eth0
  VLLM_ATTENTION_BACKEND: FLASHINFER
  VLLM_ENABLE_V1_MULTIPROCESSING: 0
  TOTAL_NUM_NODES: 1  # might be dangerous?
  TRAIN_NUM_NODES: 1  # might be dangerous?

parameters:
  seed: 17
  model:
    name: hf_critic_free_lm
    loss_type: grpo
    target_kl: 0.1
    pretrained: true
    init_device: mixed
    kl_estimator: k3
    kl_clip_range: 40
    use_auth_token: true
    compute_kl_loss: true
    policy_clip_ratio: 0.2
    attn_implementation: flash_attention_2
    normalize_advantage: true
    use_flash_attention_2: true
    length_normalize_policy_loss: true
    pretrained_model_name_or_path: deepseek-ai/DeepSeek-R1-Distill-Llama-8B
  loggers:
    mlflow:
      tags:
        run:
          run_name: null
        group: grpo
      tracking_uri: databricks
      experiment_name: /Users/ashutosh.baheti@databricks.com/mlflow_experiments/online_rl/benchmark_math/llama_8b_grpo_lr_gc_sweep1
  callbacks:
    ppo: {}
    orl_eval:
      evals:
      - name: gsm8k
      eval_overrides:
        generation_params:
          max_tokens: 8192
    lr_monitor: {}
    scheduled_gc:
      batch_interval: 1000
    speed_monitor:
      window_size: 1
    memory_monitor: {}
    hf_checkpointer:
      overwrite: true
      precision: bfloat16
      save_folder: /tmp/hf_checkpoints/
      save_interval: 1dur
    runtime_estimator: {}
  optimizer:
    lr: 1.0e-06
    name: decoupled_adamw
    betas:
    - 0.9
    - 0.95
    weight_decay: 0
  precision: amp_bf16
  scheduler:
    name: constant_with_warmup
    alpha: 1
    t_warmup: 10iter
  tokenizer:
    name: deepseek-ai/DeepSeek-R1-Distill-Llama-8B
    kwargs:
      padding: longest
      pad_token: <|finetune_right_pad_id|>
      truncation: true
      padding_side: left
      model_max_length: 10240
      trust_remote_code: true
  variables:
    gamma: 1
    buffer:
      name: MinibatchRolloutBuffer
    rewards:
      math_verifier:
        reward: 4
        reward_type: math_verifier
      bad_generation_end:
        reward: -1
        eos_penalty: true
        reward_type: bad_generation_end
      math_format_verifier:
        reward: 1
        reward_type: math_format_verifier
      penalize_extra_short_responses:
        reward: -1
        reward_type: short_response_reward
        len_threshold: 10
    lambda_gae: 1
    global_seed: 17
    max_gen_len: 8192
    eos_token_ids:
    - 128001
    - 128008
    - 128009
    kl_controller:
      kl_ctl_type: fixed
      init_kl_coef: 0
    tokenizer_name: meta-llama/Llama-3.1-8B-instruct
    num_train_nodes: 1
    reference_model:
      precision: amp_bf16
      pretrained: true
      model_config:
        name: hf_causal_lm
        pretrained: true
        use_auth_token: true
        use_flash_attention_2: true
        pretrained_model_name_or_path: deepseek-ai/DeepSeek-R1-Distill-Llama-8B
    generation_kwargs:
      top_p: 1
      do_sample: true
      use_cache: true
      temperature: 1
    epoch_per_iteration: 1
    non_train_fsdp_config:
      verbose: false
      cpu_offload: false
      mixed_precision: PURE
      state_dict_type: sharded
      use_orig_params: true
      forward_prefetch: true
      backward_prefetch: BACKWARD_PRE
      sharding_strategy: FULL_SHARD
      activation_cpu_offload: false
      activation_checkpointing: true
      activation_checkpointing_reentrant: false
    generations_per_prompt: 8
    num_batches_per_update: 8
    vllm_tensor_parallel_size: 1
    device_generate_batch_size: 1
  algorithms:
    gradient_clipping:
      clipping_type: norm
      clipping_threshold: 1
  autoresume: true
  log_config: true
  fsdp_config:
    verbose: false
    cpu_offload: false
    mixed_precision: PURE
    state_dict_type: sharded
    use_orig_params: true
    forward_prefetch: true
    backward_prefetch: BACKWARD_PRE
    sharding_strategy: FULL_SHARD
    activation_cpu_offload: false
    activation_checkpointing: true
    activation_checkpointing_reentrant: false
  max_seq_len: 10240
  save_folder: /tmp/checkpoints
  dist_timeout: 1800
  max_duration: 50iter
  progress_bar: false
  train_loader:
    name: prompt
    dataset:
      local: /tmp/dataset/prompt_{timestamp}/
      split: train
      remote: dbfs:/Volumes/datasets/ashutoshbaheti/orl_data/open_r1_filtered/dpsk_8b_open_r1_48k/
      shuffle: true
      max_gen_len: 8192
      max_seq_len: 10240
      shuffle_seed: 17
      download_timeout: 1800
    drop_last: true
    num_workers: 8
  eval_interval: 5iter
  save_interval: 100iter
  log_to_console: true
  save_overwrite: true
  python_log_level: debug
  console_log_interval: 1ba
  device_eval_batch_size: 1
  eval_subset_num_batches: -1
  global_train_batch_size: 64
  device_train_microbatch_size: 2
  save_num_checkpoints_to_keep: 1
