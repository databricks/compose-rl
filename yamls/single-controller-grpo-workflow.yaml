name: single-controller-hackathon

image: mosaicml/dle:nightly-latest
scheduling:
  priority: medium
  resumable: false
  preemptible: false
compute:
  gpus: 8
  cluster: r5z2p1
  instance: oci.bm.gpu.h200.8.oke
integrations:
- integration_type: git_repo
  path: /workspace/compose-rl
  git_repo: databricks/compose-rl
  ssh_clone: true
  git_branch: wensun/single-controller-hackathon-smd #single-controller-hackathon
- integration_type: git_repo
  path: /workspace/research-universe
  git_repo: databricks-mosaic/research-universe
  ssh_clone: true
  git_branch: update-orl-eval
command: |-
  python -m uv pip install --system /workspace/research-universe/minieval
  python -m uv pip install --system /workspace/research-universe/orl_eval
  python -m uv pip install --system /workspace/compose-rl[gpu] --no-deps

  cd /workspace/compose-rl
  composer test_single_controller_ppo.py --file_path /mnt/config/parameters.yaml

parameters:
  seed: 17
  model:
    name: hf_critic_free_lm
    loss_type: grpo #smd #grpo
    target_kl: 0.1
    beta: 1e-3  # Beta parameter for SMD regression loss
    pretrained: true
    init_device: mixed
    kl_estimator: k3
    kl_clip_range: 40
    use_auth_token: true
    compute_kl_loss: false
    policy_clip_ratio: 0.2
    attn_implementation: flash_attention_2
    allow_embedding_resizing: true
    normalize_advantage: true
    use_flash_attention_2: true
    length_normalize_policy_loss: true
    pretrained_model_name_or_path: deepseek-ai/DeepSeek-R1-Distill-Llama-8B
  loggers:
    mlflow:
      tags:
        run: test_single_controller_ppo_deepseek_l8b_open_r1_48k
        group: grpo
      tracking_uri: databricks
      experiment_name: test_single_controller_ppo
  callbacks:
    ppo: {}
    orl_eval:
      evals:
      - name: gsm8k
      - name: math_500
      - name: math_hard
      eval_overrides:
        generation_params:
          max_tokens: 8192
    lr_monitor: {}
    scheduled_gc:
      batch_interval: 1000
    speed_monitor:
      window_size: 1
    memory_monitor: {}
    hf_checkpointer:
      overwrite: true
      precision: bfloat16
      save_folder: /tmp/hf_checkpoints/
      save_interval: 1dur
    runtime_estimator: {}
  optimizer:
    lr: 1.0e-06
    name: decoupled_adamw
    betas:
    - 0.9
    - 0.95
    weight_decay: 0
  precision: amp_bf16
  scheduler:
    name: constant_with_warmup
    alpha: 1
    t_warmup: 10iter
  tokenizer:
    name: deepseek-ai/DeepSeek-R1-Distill-Llama-8B
    kwargs:
      padding: longest
      pad_token: <|finetune_right_pad_id|>
      truncation: true
      padding_side: left
      model_max_length: 10240
      trust_remote_code: true
  variables:
    gamma: 1
    buffer:
      name: MinibatchRolloutBuffer
    rewards:
      math_verifier:
        reward: 4
        reward_type: math_verifier
      bad_generation_end:
        reward: -1
        eos_penalty: true
        reward_type: bad_generation_end
      math_format_verifier:
        reward: 1
        reward_type: math_format_verifier
      penalize_extra_short_responses:
        reward: -1
        reward_type: short_response_reward
        len_threshold: 10
    lambda_gae: 1
    global_seed: 17
    max_gen_len: 8192
    eos_token_ids:
    - 128001
    - 128008
    - 128009
    kl_controller:
      kl_ctl_type: fixed
      init_kl_coef: 0
    tokenizer_name: deepseek-ai/DeepSeek-R1-Distill-Llama-8B
    num_train_nodes: 1
    reference_model:
      precision: amp_bf16
      pretrained: true
      model_config:
        name: hf_causal_lm
        pretrained: true
        use_auth_token: true
        use_flash_attention_2: true
        pretrained_model_name_or_path: deepseek-ai/DeepSeek-R1-Distill-Llama-8B
    generation_kwargs:
      top_p: 1
      do_sample: true
      use_cache: true
      temperature: 1
    epoch_per_iteration: 1
    generations_per_prompt: 8
    num_batches_per_update: 8
    device_generate_batch_size: 1
  algorithms:
    gradient_clipping:
      clipping_type: norm
      clipping_threshold: 0.001
  autoresume: true
  log_config: true
  fsdp_config:
    sync_module_states: true
    verbose: false
    cpu_offload: false
    mixed_precision: PURE
    state_dict_type: sharded
    use_orig_params: true
    forward_prefetch: true
    backward_prefetch: BACKWARD_PRE
    sharding_strategy: FULL_SHARD
    activation_cpu_offload: false
    activation_checkpointing: true
    activation_checkpointing_reentrant: false
  max_seq_len: 10240
  save_folder: /tmp/checkpoints
  dist_timeout: 1800
  max_duration: 10iter
  progress_bar: false
  train_loader:
    name: prompt
    dataset:
      local: /tmp/dataset/prompt_{timestamp}/
      split: train
      remote: dbfs:/Volumes/datasets/ashutoshbaheti/orl_data/open_r1_filtered/dpsk_8b_open_r1_48k/
      shuffle: true
      max_gen_len: 8192
      max_seq_len: 10240
      shuffle_seed: 17
      download_timeout: 1800
    drop_last: true
    num_workers: 1
  eval_interval: 10iter
  save_interval: 100iter
  eval_first: false
  log_to_console: true
  save_overwrite: true
  python_log_level: debug
  console_log_interval: 1ba
  device_eval_batch_size: 1
  eval_subset_num_batches: -1
  global_train_batch_size: 64
  device_train_microbatch_size: 1
  vllm_tensor_parallel_size: 1
  vllm_enable_prefix_caching: false
  save_num_checkpoints_to_keep: 1
  max_async_step: 0
